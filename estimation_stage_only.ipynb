{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d614d238-437b-44f0-99da-4c710e2f8309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rail\n",
    "from rail.estimation.algos.deepdisc_test import *\n",
    "from rail.core.data import TableHandle, JsonHandle, ModelHandle\n",
    "from rail.core.stage import RailStage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d53926d-78e8-4fa3-a0e8-3ec3a3fdc18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "029dedea-8be8-46a0-93a6-0b8ae840db9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"/home/g4merz/rail_deepdisc//test_informer.pkl\"\n",
    "model_handle = DS.add_data(\"model\", data=None, handle_class=ModelHandle, path=model_file)\n",
    "test_file_for_chunks = \"/home/shared/hsc/DC2/test_data/dataset_3/flattened_images_test_small.hdf5\"\n",
    "test_handle_for_chunks = DS.add_data(\"testing\", data=None, handle_class=TableHandle, path=test_file_for_chunks)\n",
    "metadatafile_with_chunks = \"/home/shared/hsc/DC2/test_data/dataset_3/test_metadata_example.hdf5\"\n",
    "metadatahandle_with_chunks = DS.add_data(\"metadata\", data=None, handle_class=Hdf5Handle, path=metadatafile_with_chunks)\n",
    "\n",
    "cfgfile = \"./configs/solo/solo_swin_DC2.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0adfc74-3159-48dc-b379-e462ae02686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_estimation_dict = dict(\n",
    "    chunk_size=5,\n",
    "    output_dir=\"./\",\n",
    "    cfgfile = cfgfile,\n",
    "    zmin=0,\n",
    "    zmax=5,\n",
    "    nzbins=200,\n",
    "    output_mode='default',\n",
    ")\n",
    "\n",
    "EstimatorWithChunks = DeepDiscPDFEstimatorWithChunking.make_stage(\n",
    "    name=\"DeepDiscEstimatorWithChunks\",\n",
    "    model=model_file,\n",
    "    **deep_estimation_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb55a78-337b-4af9-8804-436873a54074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g4merz/.conda/envs/ddrailnv/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /data/miniconda3/envs/opence-1.7/conda-bld/pytorch-base_1672876060819/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching data\n",
      "Processing chunk (start:end) - (0:5)\n",
      "0\n",
      "Matching objects - rank: 0\n",
      "\u001b[32m[01/17 16:50:00 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "Matching objects - rank: 1\n",
      "\u001b[32m[01/17 16:50:00 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/17 16:50:00 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/17 16:50:00 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/17 16:50:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.29 MiB\n",
      "\u001b[32m[01/17 16:50:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.29 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g4merz/.conda/envs/ddrailnv/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /data/miniconda3/envs/opence-1.7/conda-bld/pytorch-base_1672876060819/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/g4merz/.conda/envs/ddrailnv/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /data/miniconda3/envs/opence-1.7/conda-bld/pytorch-base_1672876060819/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned pdfs - rank: 1\n",
      "shapes (2,) (2, 200) (2,)\n",
      "1 - calling gather_object\n",
      "Returned pdfs - rank: 0\n",
      "shapes (3,) (3, 200) (3,)\n",
      "0 - making output list\n",
      "Adding PDFs to ensemble\n",
      "Adding all_pdfs to qp.Ensemble. rank - 0\n",
      "Adding ensemble to the queue. rank - 0\n",
      "Number of items in the queue: 1\n",
      "Writing out this temporary ensemble to disk\n",
      "Processing chunk (start:end) - (5:10)\n",
      "0\n",
      "Matching objects - rank: 0\n",
      "\u001b[32m[01/17 16:50:41 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "Matching objects - rank: 1\n",
      "\u001b[32m[01/17 16:50:41 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/17 16:50:41 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/17 16:50:41 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/17 16:50:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.37 MiB\n",
      "\u001b[32m[01/17 16:50:41 d2.data.common]: \u001b[0mSerialized dataset takes 1.37 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g4merz/.conda/envs/ddrailnv/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /data/miniconda3/envs/opence-1.7/conda-bld/pytorch-base_1672876060819/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/g4merz/.conda/envs/ddrailnv/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /data/miniconda3/envs/opence-1.7/conda-bld/pytorch-base_1672876060819/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned pdfs - rank: 1\n",
      "shapes (4,) (4, 200) (4,)\n",
      "1 - calling gather_object\n",
      "Returned pdfs - rank: 0\n",
      "shapes (5,) (5, 200) (5,)\n",
      "0 - making output list\n",
      "Adding PDFs to ensemble\n",
      "Adding all_pdfs to qp.Ensemble. rank - 0\n",
      "Adding ensemble to the queue. rank - 0\n",
      "Number of items in the queue: 1\n",
      "Writing out this temporary ensemble to disk\n",
      "Inserting handle into data store.  output_DeepDiscEstimatorWithChunks: inprogress_output_DeepDiscEstimatorWithChunks.hdf5, DeepDiscEstimatorWithChunks\n"
     ]
    }
   ],
   "source": [
    "results_from_chunks = EstimatorWithChunks.estimate(test_handle_for_chunks, metadatahandle_with_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bab95c9-2dab-48a1-a9a6-da272e586c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ens = results_from_chunks.read()\n",
    "res_ens.npdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc284e-7701-4a72-8370-49a405a71cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(0,3,100)\n",
    "ax.plot(x, res_ens[0].pdf(x)[0])\n",
    "ax.plot(x, res_ens[1].pdf(x)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ddrailnv]",
   "language": "python",
   "name": "conda-env-.conda-ddrailnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
