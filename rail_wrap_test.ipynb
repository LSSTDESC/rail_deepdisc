{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c2a2dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drewoldag/.conda/envs/rail_deepdisc39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Training script for LazyConfig models\n",
    "try:\n",
    "    # ignore ShapelyDeprecationWarning from fvcore\n",
    "    import warnings\n",
    "\n",
    "    from shapely.errors import ShapelyDeprecationWarning\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning)\n",
    "\n",
    "except:\n",
    "    pass\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "\n",
    "import detectron2.utils.comm as comm\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.config import LazyConfig, get_cfg\n",
    "import detectron2.data as data\n",
    "from detectron2.engine import (\n",
    "    launch,\n",
    ")\n",
    "\n",
    "from deepdisc.data_format.augment_image import train_augs\n",
    "from deepdisc.data_format.image_readers import DC2ImageReader\n",
    "from deepdisc.data_format.register_data import (\n",
    "    register_data_set,\n",
    ")  # , register_loaded_data_set\n",
    "from deepdisc.model.loaders import (\n",
    "    RedshiftFlatDictMapper,\n",
    "    return_test_loader,\n",
    "    return_train_loader,\n",
    ")\n",
    "from deepdisc.model.models import (\n",
    "    RedshiftPointCasROIHeads,\n",
    "    RedshiftPointROIHeads,\n",
    "    RedshiftPDFROIHeads,\n",
    "    return_lazy_model,\n",
    ")\n",
    "from deepdisc.training.trainers import (\n",
    "    return_evallosshook,\n",
    "    return_lazy_trainer,\n",
    "    return_optimizer,\n",
    "    return_savehook,\n",
    "    return_schedulerhook,\n",
    ")\n",
    "from deepdisc.utils.parse_arguments import make_training_arg_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46af65a-b45d-4455-92d6-d2d68dd89eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 19 00:02:47 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-16GB           On  | 00000004:04:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              38W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-16GB           On  | 00000035:03:00.0 Off |                    0 |\n",
      "| N/A   29C    P0              37W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5244b7ff-1501-47ad-b74e-c575f9758089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rail.estimation.algos.deepdisc import DeepDiscInformer\n",
    "import rail\n",
    "from rail.estimation.algos.deepdisc import *\n",
    "from rail.core.data import TableHandle, JsonHandle\n",
    "from rail.core.stage import RailStage\n",
    "\n",
    "from rail.deepdisc.configs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e82e6de-f6ec-46b5-a6a7-60e79cd79c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/shared/hsc/DC2/test_data/dataset_3/flattened_images_train_small.npy\n",
    "cfgfile = \"/home/shared/hsc/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.py\"\n",
    "dirpath = \"./tests/deepdisc/test_data/dc2/\"\n",
    "output_dir = \"./\"\n",
    "output_name = \"test\"\n",
    "\n",
    "# trainfile = dirpath + \"flattened_data_test.npy\"\n",
    "trainfile = \"/home/shared/hsc/DC2/test_data/dataset_3/flattened_images_train.hdf5\"\n",
    "testfile = \"/home/shared/hsc/DC2/test_data/dataset_3/flattened_images_test.hdf5\"\n",
    "metadatafile = \"/home/shared/hsc/DC2/test_data/dataset_3/train_metadata.json\"\n",
    "test_metadatafile = \"/home/shared/hsc/DC2/test_data/dataset_3/test_metadata.json\"\n",
    "\n",
    "classes = [\"object\"]\n",
    "numclasses = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ed14575-d55b-4400-90f9-752f27cc75c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'detectron2://ImageNetPretrained/MSRA/R-50.pkl'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = get_lazy_config(cfgfile, 1, 1)\n",
    "cfg.train.init_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd06982-1e98-4b8a-a3a8-b68ac71cd6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c476d78e-9c5d-44a5-9489-de1b9e0d39f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9940c5c2-b692-4e3b-a595-0afec0c21e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepdisc.data_format.file_io import get_data_from_json\n",
    "\n",
    "# testdata = np.load(trainfile, allow_pickle=True)\n",
    "# testdata = DS.read_file(\"testdata\", TableHandle, trainfile)\n",
    "metadata = get_data_from_json(metadatafile)\n",
    "test_metadata = get_data_from_json(test_metadatafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01f48f9e-16a3-423d-a550-ed9298b6fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training = DS.add_data(\"training\", testdata(), TableHandle, path=trainfile) #()[\"images\"]\n",
    "# testing = DS.add_data(\"testing\", testdata, TableHandle)\n",
    "\n",
    "training = DS.add_data(\n",
    "    \"training\", data=None, handle_class=TableHandle, path=trainfile\n",
    ")  # ()[\"images\"]\n",
    "testing = DS.add_data(\"testing\", data=None, handle_class=TableHandle, path=testfile)\n",
    "\n",
    "metadatahandle = DS.add_data(\"metadata\", metadata, JsonHandle, path=metadatafile)\n",
    "# metadatahandle = DS.add_data(\"test_metadata\", test_metadata, JsonHandle, path=test_metadatafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a57e206a-c5c6-4526-a278-868ef2a6047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_dict = dict(\n",
    "    cfgfile=\"/home/shared/hsc/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.py\",\n",
    "    num_gpus=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d611ae20-a7c7-4f52-9390-1d27eca138f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inform = DeepDiscInformer.make_stage(name='Inform_DeepDISC', model='detectron2://ImageNetPretrained/MSRA/R-50.pkl', **deep_dict)\n",
    "Inform = DeepDiscInformer.make_stage(\n",
    "    name=\"Inform_DeepDISC\", \n",
    "    model=\"deepdisc_informer.pkl\", # Important that this has a name different than the .pth model weights file.\n",
    "    **deep_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4924105-cdc7-4d7d-a4a6-89fea0545313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import LazyConfig, get_cfg\n",
    "\n",
    "cfg = LazyConfig.load(cfgfile)\n",
    "cfg.train.init_checkpoint = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87b6a9d1-697e-4bde-abee-e519253daa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching data\n",
      "Training head layers\n",
      "In launch function\n",
      "World size: 1\n",
      "\u001b[32m[12/19 00:05:04 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[12/19 00:05:04 d2.data.common]: \u001b[0mSerializing 800 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/19 00:05:21 d2.data.common]: \u001b[0mSerialized dataset takes 220.12 MiB\n",
      "\u001b[32m[12/19 00:05:21 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=1\n",
      "\u001b[32m[12/19 00:05:21 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[12/19 00:05:21 d2.data.common]: \u001b[0mSerializing 200 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/19 00:05:23 d2.data.common]: \u001b[0mSerialized dataset takes 54.65 MiB\n",
      "\u001b[32m[12/19 00:05:30 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from None ...\n",
      "\u001b[32m[12/19 00:05:30 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "<detectron2.solver.lr_scheduler.LRMultiplier object at 0x7ff6a719f0d0>\n",
      "saving deepdisc_informer\n",
      "Training full model\n",
      "In launch function\n",
      "World size: 1\n",
      "\u001b[32m[12/19 00:05:30 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[12/19 00:05:30 d2.data.common]: \u001b[0mSerializing 800 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/19 00:05:42 d2.data.common]: \u001b[0mSerialized dataset takes 220.12 MiB\n",
      "\u001b[32m[12/19 00:05:42 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=1\n",
      "\u001b[32m[12/19 00:05:43 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[12/19 00:05:43 d2.data.common]: \u001b[0mSerializing 200 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/19 00:05:44 d2.data.common]: \u001b[0mSerialized dataset takes 54.65 MiB\n",
      "\u001b[32m[12/19 00:05:45 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./deepdisc_informer.pth ...\n",
      "\u001b[32m[12/19 00:05:45 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "<detectron2.solver.lr_scheduler.LRMultiplier object at 0x7ff6a7292820>\n",
      "saving deepdisc_informer\n",
      "Inserting handle into data store.  model_Inform_DeepDISC: inprogress_deepdisc_informer.pkl, Inform_DeepDISC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rail.core.data.ModelHandle at 0x7ff6949d6fd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inform.inform(training, metadatahandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebe37e07-635f-4677-beac-2b978581646f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rail.core.data.ModelHandle at 0x7ff6949d6fd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Inform.get_handle(\"model\")\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6898f5c-a6b5-44ca-9621-1e1fdc227222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import detectron2.checkpoint as checkpointer\n",
    "\n",
    "cfgfile=\"/home/shared/hsc/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.py\"\n",
    "cfg = get_lazy_config(cfgfile, 1, 1)\n",
    "\n",
    "model = instantiate(cfg.model)\n",
    "\n",
    "# cp = checkpointer.DetectionCheckpointer(model,\"./\")\n",
    "# # load weights\n",
    "file_path = os.path.join(\"./\", \"deepdisc_informer\" + \".pth\")\n",
    "# weights = cp.load(file_path)\n",
    "# weights\n",
    "\n",
    "from fvcore.common.checkpoint import Checkpointer\n",
    "fv_cp = Checkpointer(model, \"./\")\n",
    "other_weights = fv_cp._load_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb810a68-37e8-432e-90e2-3263fddba8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=[], incorrect_shapes=[])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cfgfile=\"/home/shared/hsc/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.py\"\n",
    "cfg = get_lazy_config(cfgfile, 1, 1)\n",
    "\n",
    "model = instantiate(cfg.model)\n",
    "fv_cp = Checkpointer(model, \"./\")\n",
    "fv_cp._load_model(other_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c69b958",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7070dcb2-0de8-42af-af8d-f40c689b7cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatahandle = DS.add_data(\n",
    "    \"metadata\", test_metadata, JsonHandle, path=test_metadatafile\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7360caf2-5b3d-4998-be0c-3ca28fb5e035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StageConfig{cfgfile:/home/shared/hsc/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.py,batch_size:1,numclasses:1,epochs:20,output_dir:./,output_name:deepdisc_estimator,chunk_size:100,num_camera_filters:6,name:DeepDiscEstimator,model:<class 'rail.core.data.ModelHandle'> deepdisc_informer.pkl, (wd),num_gpus:1,config:None,input:None,metadata:None,aliases:{'output': 'output_DeepDiscEstimator', 'truth': 'truth_DeepDiscEstimator'},}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimator = DeepDiscEstimator.make_stage(name='DeepDiscEstimator',\n",
    "#                                       model=Inform.get_handle('model'), **deep_dict)\n",
    "\n",
    "Estimator = DeepDiscPDFEstimator.make_stage(\n",
    "    name=\"DeepDiscEstimator\",\n",
    "    model=Inform.get_handle(\"model\"),\n",
    "    **deep_dict,\n",
    ")\n",
    "Estimator.config\n",
    "# Inform.get_handle(\"model\").has_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c74bb222-f53c-415c-acab-f8b978a2af5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching data\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "return_predictor_transformer() got an unexpected keyword argument 'checkpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mEstimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtesting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatahandle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/rail_deepdisc/src/rail/estimation/algos/deepdisc.py:372\u001b[0m, in \u001b[0;36mDeepDiscPDFEstimator.estimate\u001b[0;34m(self, input_data, input_metadata)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_data)\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_metadata)\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize()\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_handle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/code/rail_deepdisc/src/rail/estimation/algos/deepdisc.py:418\u001b[0m, in \u001b[0;36mDeepDiscPDFEstimator.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m cfg_loader \u001b[38;5;241m=\u001b[39m get_loader_config(output_dir, batch_size)\n\u001b[1;32m    416\u001b[0m cfg\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39minit_checkpoint \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, output_name) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor \u001b[38;5;241m=\u001b[39m \u001b[43mreturn_predictor_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnnmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Process test images same way as training set\u001b[39;00m\n\u001b[1;32m    421\u001b[0m mapper \u001b[38;5;241m=\u001b[39m RedshiftDictMapper(\n\u001b[1;32m    422\u001b[0m     DC2ImageReader(), \u001b[38;5;28;01mlambda\u001b[39;00m dataset_dict: dataset_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    423\u001b[0m )\u001b[38;5;241m.\u001b[39mmap_data\n",
      "\u001b[0;31mTypeError\u001b[0m: return_predictor_transformer() got an unexpected keyword argument 'checkpoint'"
     ]
    }
   ],
   "source": [
    "results = Estimator.estimate(testing, metadatahandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b402ba2-3779-44e7-8654-113f19731464",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = results.read()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d2b4a5-0422-4f8f-8e08-49811549c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = Estimator.get_handle(\"truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94da4c4a-93c6-4203-a1b3-4fe186bad242",
   "metadata": {},
   "outputs": [],
   "source": [
    "ztrue = truth.data[\"redshift\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b958d33f-c330-4149-aa97-fe1970555bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.evaluation.evaluator import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e185eb-397a-41b8-978e-871a9f624cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_eval_dict = dict(\n",
    "    chunk_size=100,\n",
    "    zmin=-1,\n",
    "    zmax=5,\n",
    "    nzbins=200,\n",
    "    epochs=20,\n",
    "    output_name=\"test_evaluator\",\n",
    "    point_metrics=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7417fa3-0c51-4a04-837c-f9e54431eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepEvaluator = Evaluator.make_stage(name=\"DeepDiscEvaluator\", **deep_eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ba5ca0-7ded-4b4c-ac63-264c8c23ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_res = DeepEvaluator.evaluate(res, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf80908-9582-45ca-b78f-f5163fb415a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_res.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f874ba48-786b-46d9-845d-d659c86cdc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qp.metrics.pit import PIT\n",
    "from utils import *  # plot_pit_qq, ks_plot\n",
    "\n",
    "pitobj = PIT(res, ztrue)\n",
    "pit_out_rate = pitobj.evaluate_PIT_outlier_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6de28b4-61c2-4d6f-ab20-46a0d369364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qp.ensemble import Ensemble\n",
    "\n",
    "\n",
    "class Sample(Ensemble):\n",
    "    \"\"\"Expand qp.Ensemble to append true redshifts\n",
    "    array, metadata, and specific plots.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, pdfs, zgrid, ztrue, photoz_mode=None, code=\"\", name=\"\", n_quant=100\n",
    "    ):\n",
    "        \"\"\"Class constructor\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pdfs: `ndarray`\n",
    "            photo-z PDFs array, shape=(Ngals, Nbins)\n",
    "        zgrid: `ndarray`\n",
    "            PDF bins centers, shape=(Nbins,)\n",
    "        ztrue: `ndarray`\n",
    "            true redshifts, shape=(Ngals,)\n",
    "        photoz_mode: `ndarray`\n",
    "            photo-z (PDF mode), shape=(Ngals,)\n",
    "        code: `str`, (optional)\n",
    "            algorithm name (for plot legends)\n",
    "        name: `str`, (optional)\n",
    "            sample name (for plot legends)\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(interp, data=dict(xvals=zgrid, yvals=pdfs))\n",
    "        self._pdfs = pdfs\n",
    "        self._zgrid = zgrid\n",
    "        self._ztrue = ztrue\n",
    "        self._photoz_mode = photoz_mode\n",
    "        self._code = code\n",
    "        self._name = name\n",
    "        self._n_quant = n_quant\n",
    "        self._pit = None\n",
    "        self._qq = None\n",
    "\n",
    "    @property\n",
    "    def code(self):\n",
    "        \"\"\"Photo-z code/algorithm name\"\"\"\n",
    "        return self._code\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        \"\"\"Sample name\"\"\"\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def ztrue(self):\n",
    "        \"\"\"True redshifts array\"\"\"\n",
    "        return self._ztrue\n",
    "\n",
    "    @property\n",
    "    def zgrid(self):\n",
    "        \"\"\"Redshift grid (binning)\"\"\"\n",
    "        return self._zgrid\n",
    "\n",
    "    @property\n",
    "    def photoz_mode(self):\n",
    "        \"\"\"Photo-z (mode) array\"\"\"\n",
    "        return self._photoz_mode\n",
    "\n",
    "    @property\n",
    "    def n_quant(self):\n",
    "        return self._n_quant\n",
    "\n",
    "    @property\n",
    "    def pit(self):\n",
    "        if self._pit is None:\n",
    "            pit_array = np.array(\n",
    "                [self[i].cdf(self.ztrue[i])[0][0] for i in range(len(self))]\n",
    "            )\n",
    "            self._pit = pit_array\n",
    "        return self._pit\n",
    "\n",
    "    @property\n",
    "    def qq(self, n_quant=100):\n",
    "        q_theory = np.linspace(0.0, 1.0, n_quant)\n",
    "        q_data = np.quantile(self.pit, q_theory)\n",
    "        self._qq = (q_theory, q_data)\n",
    "        return self._qq\n",
    "\n",
    "    def __len__(self):\n",
    "        if len(self._ztrue) != len(self._pdfs):\n",
    "            raise ValueError(\"Number of pdfs and true redshifts do not match!!!\")\n",
    "        return len(self._ztrue)\n",
    "\n",
    "    def __str__(self):\n",
    "        code_str = f\"Algorithm: {self._code}\"\n",
    "        name_str = f\"Sample: {self._name}\"\n",
    "        line_str = \"-\" * (max(len(code_str), len(name_str)))\n",
    "        text = str(\n",
    "            line_str\n",
    "            + \"\\n\"\n",
    "            + name_str\n",
    "            + \"\\n\"\n",
    "            + code_str\n",
    "            + \"\\n\"\n",
    "            + line_str\n",
    "            + \"\\n\"\n",
    "            + f\"{len(self)} PDFs with {len(self.zgrid)} probabilities each \\n\"\n",
    "            + f\"qp representation: {self.gen_class.name} \\n\"\n",
    "            + f\"z grid: {len(self.zgrid)} z values from {np.min(self.zgrid)} to {np.max(self.zgrid)} inclusive\"\n",
    "        )\n",
    "        return text\n",
    "\n",
    "    def plot_pdfs(self, gals, show_ztrue=True, show_photoz_mode=False):\n",
    "        colors = plot_pdfs(\n",
    "            self, gals, show_ztrue=show_ztrue, show_photoz_mode=show_photoz_mode\n",
    "        )\n",
    "        return colors\n",
    "\n",
    "    def plot_old_valid(self, gals=None, colors=None):\n",
    "        old_metrics_table = plot_old_valid(self, gals=gals, colors=colors)\n",
    "        return old_metrics_table\n",
    "\n",
    "    def plot_pit_qq(\n",
    "        self,\n",
    "        bins=None,\n",
    "        label=None,\n",
    "        title=None,\n",
    "        show_pit=True,\n",
    "        show_qq=True,\n",
    "        show_pit_out_rate=True,\n",
    "        savefig=False,\n",
    "    ):\n",
    "        \"\"\"Make plot PIT-QQ as Figure 2 from Schmidt et al. 2020.\"\"\"\n",
    "        fig_filename = plot_pit_qq(\n",
    "            self,\n",
    "            bins=bins,\n",
    "            label=label,\n",
    "            title=title,\n",
    "            show_pit=show_pit,\n",
    "            show_qq=show_qq,\n",
    "            show_pit_out_rate=show_pit_out_rate,\n",
    "            savefig=savefig,\n",
    "        )\n",
    "        return fig_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee26258c-8401-45ed-a75d-92da6ed7f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pit_qq(\n",
    "    pdfs,\n",
    "    zgrid,\n",
    "    ztrue,\n",
    "    bins=None,\n",
    "    title=None,\n",
    "    code=None,\n",
    "    show_pit=True,\n",
    "    show_qq=True,\n",
    "    pit_out_rate=None,\n",
    "    savefig=False,\n",
    ") -> str:\n",
    "    \"\"\"Quantile-quantile plot\n",
    "        Ancillary function to be used by class Metrics.\n",
    "    â€‹\n",
    "        Parameters\n",
    "        ----------\n",
    "        pit: `PIT` object\n",
    "            class from metrics.py\n",
    "        bins: `int`, optional\n",
    "            number of PIT bins\n",
    "            if None, use the same number of quantiles (sample.n_quant)\n",
    "        title: `str`, optional\n",
    "            if None, use formatted sample's name (sample.name)\n",
    "        label: `str`, optional\n",
    "            if None, use formatted code's name (sample.code)\n",
    "        show_pit: `bool`, optional\n",
    "            include PIT histogram (default=True)\n",
    "        show_qq: `bool`, optional\n",
    "            include QQ plot (default=True)\n",
    "        pit_out_rate: `ndarray`, optional\n",
    "            print metric value on the plot panel (default=None)\n",
    "        savefig: `bool`, optional\n",
    "            save plot in .png file (default=False)\n",
    "    \"\"\"\n",
    "\n",
    "    if bins is None:\n",
    "        bins = 100\n",
    "    if title is None:\n",
    "        title = \"\"\n",
    "\n",
    "    if code is None:\n",
    "        code = \"\"\n",
    "        label = \"\"\n",
    "    else:\n",
    "        label = code + \"\\n\"\n",
    "\n",
    "    if pit_out_rate is not None:\n",
    "        try:\n",
    "            label += \"PIT$_{out}$: \"\n",
    "            label += f\"{float(pit_out_rate):.4f}\"\n",
    "        except:\n",
    "            print(\"Unsupported format for pit_out_rate.\")\n",
    "\n",
    "    plt.figure(figsize=[4, 5])\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[3, 1])\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    sample = Sample(pdfs, zgrid, ztrue)\n",
    "\n",
    "    if show_qq:\n",
    "        ax0.plot(\n",
    "            sample.qq[0], sample.qq[1], c=\"r\", linestyle=\"-\", linewidth=3, label=label\n",
    "        )\n",
    "        ax0.plot([0, 1], [0, 1], color=\"k\", linestyle=\"--\", linewidth=2)\n",
    "        ax0.set_ylabel(\"Q$_{data}$\", fontsize=18)\n",
    "        plt.ylim(-0.001, 1.001)\n",
    "    plt.xlim(-0.001, 1.001)\n",
    "    plt.title(title)\n",
    "    if show_pit:\n",
    "        fzdata = Ensemble(interp, data=dict(xvals=zgrid, yvals=pdfs))\n",
    "        pitobj = PIT(fzdata, ztrue)\n",
    "        pit_vals = np.array(pitobj.pit_samps)\n",
    "        pit_out_rate = pitobj.evaluate_PIT_outlier_rate()\n",
    "\n",
    "        try:\n",
    "            y_uni = float(len(pit_vals)) / float(bins)\n",
    "        except:\n",
    "            y_uni = float(len(pit_vals)) / float(len(bins))\n",
    "        if not show_qq:\n",
    "            ax0.hist(pit_vals, bins=bins, alpha=0.7, label=label)\n",
    "            ax0.set_ylabel(\"Number\")\n",
    "            ax0.hlines(y_uni, xmin=0, xmax=1, color=\"k\")\n",
    "            plt.ylim(\n",
    "                0,\n",
    "            )  # -0.001, 1.001)\n",
    "        else:\n",
    "            ax1 = ax0.twinx()\n",
    "            ax1.hist(pit_vals, bins=bins, alpha=0.7)\n",
    "            ax1.set_ylabel(\"Number\")\n",
    "            ax1.hlines(y_uni, xmin=0, xmax=1, color=\"k\")\n",
    "    leg = ax0.legend(handlelength=0, handletextpad=0, fancybox=True)\n",
    "    for item in leg.legendHandles:\n",
    "        item.set_visible(False)\n",
    "    if show_qq:\n",
    "        ax2 = plt.subplot(gs[1])\n",
    "        ax2.plot(\n",
    "            sample.qq[0],\n",
    "            (sample.qq[1] - sample.qq[0]),\n",
    "            c=\"r\",\n",
    "            linestyle=\"-\",\n",
    "            linewidth=3,\n",
    "        )\n",
    "        plt.ylabel(\"$\\Delta$Q\", fontsize=18)\n",
    "        ax2.plot([0, 1], [0, 0], color=\"k\", linestyle=\"--\", linewidth=2)\n",
    "        plt.xlim(-0.001, 1.001)\n",
    "        plt.ylim(\n",
    "            np.min([-0.12, np.min(sample.qq[1] - sample.qq[0]) * 1.05]),\n",
    "            np.max([0.12, np.max(sample.qq[1] - sample.qq[0]) * 1.05]),\n",
    "        )\n",
    "    if show_pit:\n",
    "        if show_qq:\n",
    "            plt.xlabel(\"Q$_{theory}$ / PIT Value\", fontsize=18)\n",
    "        else:\n",
    "            plt.xlabel(\"PIT Value\", fontsize=18)\n",
    "    else:\n",
    "        if show_qq:\n",
    "            plt.xlabel(\"Q$_{theory}$\", fontsize=18)\n",
    "    if savefig:\n",
    "        fig_filename = str(\"plot_pit_qq_\" + f\"{(code).replace(' ', '_')}.png\")\n",
    "        plt.savefig(fig_filename)\n",
    "    else:\n",
    "        fig_filename = None\n",
    "\n",
    "    return fig_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1263c0-1b38-4042-956c-902f1065c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from qp import interp\n",
    "\n",
    "\n",
    "zgrid = np.linspace(-1, 5, 200)\n",
    "pdfs = res.objdata()[\"yvals\"]\n",
    "plot_pit_qq(\n",
    "    pdfs,\n",
    "    zgrid,\n",
    "    ztrue,\n",
    "    title=\"PIT-QQ - toy data\",\n",
    "    code=\"DeepDISC\",\n",
    "    pit_out_rate=pit_out_rate,\n",
    "    savefig=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb4cfe-af95-45f1-91f1-ed9c08009f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.objdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78982146-0b5d-49d3-bb04-77931ea3aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b2cf39-8446-4888-b304-85637c2fba92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rail_deepdisc39",
   "language": "python",
   "name": "rail_deepdisc39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
