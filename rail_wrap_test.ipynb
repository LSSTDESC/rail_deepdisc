{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c2a2dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drewoldag/.conda/envs/rail_deepdisc39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Training script for LazyConfig models\n",
    "try:\n",
    "    # ignore ShapelyDeprecationWarning from fvcore\n",
    "    import warnings\n",
    "\n",
    "    from shapely.errors import ShapelyDeprecationWarning\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning)\n",
    "\n",
    "except:\n",
    "    pass\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "\n",
    "import detectron2.utils.comm as comm\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.config import LazyConfig, get_cfg\n",
    "import detectron2.data as data\n",
    "from detectron2.engine import (\n",
    "    launch,\n",
    ")\n",
    "\n",
    "from deepdisc.data_format.augment_image import train_augs\n",
    "from deepdisc.data_format.image_readers import DC2ImageReader\n",
    "from deepdisc.data_format.register_data import (\n",
    "    register_data_set,\n",
    ")  # , register_loaded_data_set\n",
    "from deepdisc.model.loaders import (\n",
    "    RedshiftFlatDictMapper,\n",
    "    return_test_loader,\n",
    "    return_train_loader,\n",
    ")\n",
    "from deepdisc.model.models import (\n",
    "    RedshiftPointCasROIHeads,\n",
    "    RedshiftPointROIHeads,\n",
    "    RedshiftPDFROIHeads,\n",
    "    return_lazy_model,\n",
    ")\n",
    "from deepdisc.training.trainers import (\n",
    "    return_evallosshook,\n",
    "    return_lazy_trainer,\n",
    "    return_optimizer,\n",
    "    return_savehook,\n",
    "    return_schedulerhook,\n",
    ")\n",
    "from deepdisc.utils.parse_arguments import make_training_arg_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6167f21e-0bbc-45cb-bc06-aac14f765fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(rail.estimation.algos.deepdisc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5244b7ff-1501-47ad-b74e-c575f9758089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rail.estimation.algos.deepdisc import DeepDiscInformer\n",
    "import rail\n",
    "from rail.estimation.algos.deepdisc import *\n",
    "from rail.core.data import TableHandle, JsonHandle\n",
    "from rail.core.stage import RailStage\n",
    "\n",
    "from rail.deepdisc.configs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e82e6de-f6ec-46b5-a6a7-60e79cd79c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/home/shared/hsc/DC2/test_data/dataset_3/flattened_images_train_small.npy\n",
    "cfgfile = \"/home/shared/hsc/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.py\"\n",
    "dirpath = \"./tests/deepdisc/test_data/dc2/\"\n",
    "output_dir = \"./\"\n",
    "output_name = \"test\"\n",
    "\n",
    "#trainfile = dirpath + \"flattened_data_test.npy\"\n",
    "trainfile = \"/home/shared/hsc/DC2/test_data/dataset_3/flattened_images_train.hdf5\"\n",
    "testfile = dirpath + \"flattened_data_test.npy\"\n",
    "metadatafile = \"/home/shared/hsc/DC2/test_data/dataset_3/train_metadata.json\"\n",
    "classes = [\"object\"]\n",
    "numclasses = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ed14575-d55b-4400-90f9-752f27cc75c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'detectron2://ImageNetPretrained/MSRA/R-50.pkl'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = get_lazy_config(cfgfile, 1, 1)\n",
    "cfg.train.init_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd06982-1e98-4b8a-a3a8-b68ac71cd6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9940c5c2-b692-4e3b-a595-0afec0c21e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepdisc.data_format.file_io import get_data_from_json\n",
    "\n",
    "#testdata = np.load(trainfile, allow_pickle=True)\n",
    "testdata = DS.read_file(\"testdata\", TableHandle, trainfile)\n",
    "metadata = get_data_from_json(metadatafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef5887b5-f2d2-4047-8d81-af04dfa54bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testdata = np.load(\"./tests/deepdisc/test_data/dc2/flattened_data_test.npy\")\n",
    "mapper = RedshiftFlatDictMapper().map_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12521313-e75d-4ebb-afd4-03d65a3d6931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('images',\n",
       "              array([[-0.12334768, -0.02265165, -0.08154224, ...,  0.11944132,\n",
       "                       0.26857075, -0.44378543],\n",
       "                     [-0.12334768, -0.02265165, -0.08154224, ...,  0.11944132,\n",
       "                       0.26857075, -0.44378543],\n",
       "                     [-0.12334768, -0.02265165, -0.08154224, ...,  0.11944132,\n",
       "                       0.26857075, -0.44378543],\n",
       "                     ...,\n",
       "                     [-0.12334768, -0.02265165, -0.08154224, ...,  0.11944132,\n",
       "                       0.26857075, -0.44378543],\n",
       "                     [-0.12334768, -0.02265165, -0.08154224, ...,  0.11944132,\n",
       "                       0.26857075, -0.44378543],\n",
       "                     [-0.12334768, -0.02265165, -0.08154224, ...,  0.11944132,\n",
       "                       0.26857075, -0.44378543]], dtype=float32))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7e9a2e4-0bae-4b0d-9e62-60fd09795e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dicts = {}\n",
    "# dds = []\n",
    "# for row in testdata:\n",
    "#     dds.append(mapper(row))\n",
    "# dataset_dicts[\"test\"] = dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01f48f9e-16a3-423d-a550-ed9298b6fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = DS.add_data(\"training\", testdata(), TableHandle, path=trainfile) #()[\"images\"]\n",
    "testing = DS.add_data(\"testing\", testdata, TableHandle)\n",
    "\n",
    "metadatahandle = DS.add_data(\"metadata\", metadata, JsonHandle, path=metadatafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd1e520f-617e-4a5a-91ec-0c98cf037c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['images']>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File(trainfile, 'r')\n",
    "\n",
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9fcdcff-6bb5-474b-8f91-8904a6211f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rail.core.data.TableHandle at 0x7ff6ebc89d90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4b8aad5-1fcd-4ab1-a843-899c8913e297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'rail.core.data.TableHandle'> /home/shared/hsc/DC2/test_data/dataset_3/flattened_images_train.hdf5, (wd)\n"
     ]
    }
   ],
   "source": [
    "print(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a57e206a-c5c6-4526-a278-868ef2a6047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_dict = dict(\n",
    "    chunk_size=100,\n",
    "    epochs=200,\n",
    "    numclasses=1,\n",
    "    batch_size=1,\n",
    "    output_dir=\"./\",\n",
    "    cfgfile=\"/home/shared/hsc/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.py\",\n",
    "    output_name=\"test_informer\",\n",
    "#     hdf5_groupname=\"images\",\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d611ae20-a7c7-4f52-9390-1d27eca138f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inform = DeepDiscInformer.make_stage(name='Inform_DeepDISC', model='detectron2://ImageNetPretrained/MSRA/R-50.pkl', **deep_dict)\n",
    "Inform = DeepDiscInformer.make_stage(\n",
    "    name=\"Inform_DeepDISC\", model=\"test_informer.pkl\", **deep_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87b6a9d1-697e-4bde-abee-e519253daa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/06 15:13:11 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[12/06 15:13:11 d2.data.common]: \u001b[0mSerializing 1000 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/06 15:13:22 d2.data.common]: \u001b[0mSerialized dataset takes 274.77 MiB\n",
      "\u001b[32m[12/06 15:13:22 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=1\n",
      "\u001b[32m[12/06 15:13:23 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[12/06 15:13:23 d2.data.common]: \u001b[0mSerializing 1000 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/06 15:13:33 d2.data.common]: \u001b[0mSerialized dataset takes 274.77 MiB\n",
      "\u001b[32m[12/06 15:13:34 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...\n",
      "\u001b[32m[12/06 15:13:34 d2.checkpoint.c2_model_loading]: \u001b[0mRenaming Caffe2 weights ......\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:13:34 d2.checkpoint.c2_model_loading]: \u001b[0mShape of stem.conv1.weight in checkpoint is torch.Size([64, 3, 7, 7]), while shape of backbone.bottom_up.stem.conv1.weight in model is torch.Size([64, 6, 7, 7]).\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/06 15:13:34 d2.checkpoint.c2_model_loading]: \u001b[0mstem.conv1.weight will not be loaded. Please double check and see if this is desired.\n",
      "\u001b[32m[12/06 15:13:34 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with submodule backbone.bottom_up - Total num: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mbackbone.bottom_up.stem.conv1.weight\u001b[0m\n",
      "\u001b[34mbackbone.fpn_lateral2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.fpn_lateral3.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.fpn_lateral4.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.fpn_lateral5.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.fpn_output2.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.fpn_output3.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.fpn_output4.{bias, weight}\u001b[0m\n",
      "\u001b[34mbackbone.fpn_output5.{bias, weight}\u001b[0m\n",
      "\u001b[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}\u001b[0m\n",
      "\u001b[34mproposal_generator.rpn_head.conv.{bias, weight}\u001b[0m\n",
      "\u001b[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_head.fc1.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_head.fc2.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.deconv.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.mask_fcn1.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.mask_fcn2.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.mask_fcn3.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.mask_fcn4.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.redshift_fc.0.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.redshift_fc.2.{bias, weight}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mfc1000.{bias, weight}\u001b[0m\n",
      "  \u001b[35mstem.conv1.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training:\n",
      "\u001b[32m[12/06 15:13:34 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "<detectron2.solver.lr_scheduler.LRMultiplier object at 0x7ff6cc150dc0>\n",
      "Iteration:  5  time:  2.260785549879074e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5425099730491638, 0.21780839562416077, 0.10481711477041245, 0.5889551639556885, 0.23823335766792297] val loss:  0 lr:  [0.001]\n",
      "Iteration:  10  time:  1.5902332961559296e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5010473728179932, 0.17743214964866638, 0.09842608124017715, 0.36248016357421875, 0.24596776068210602] val loss:  0 lr:  [0.001]\n",
      "Iteration:  15  time:  2.759043127298355e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.808623194694519, 0.36287716031074524, 0.09668457508087158, 0.2638605237007141, 0.23049607872962952] val loss:  0 lr:  [0.001]\n",
      "Iteration:  20  time:  3.110617399215698e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5823343992233276, 0.30530494451522827, 0.09962335228919983, 0.22936929762363434, 0.1860545575618744] val loss:  0 lr:  [0.001]\n",
      "Iteration:  25  time:  2.4191103875637054e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5498154163360596, 0.14023995399475098, 0.0869804322719574, 0.1830458790063858, 0.2650827169418335] val loss:  0 lr:  [0.001]\n",
      "Iteration:  30  time:  2.5192275643348694e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.531527042388916, 0.3973654508590698, 0.10075327008962631, 0.1830415278673172, 0.2516728341579437] val loss:  0 lr:  [0.001]\n",
      "Iteration:  35  time:  1.778826117515564e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5469704270362854, 0.4608219861984253, 0.07991793751716614, 0.15214091539382935, 0.2228631228208542] val loss:  0 lr:  [0.001]\n",
      "Iteration:  40  time:  2.561137080192566e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5137604475021362, 0.21827833354473114, 0.08877433091402054, 0.13805554807186127, 0.2135871797800064] val loss:  0 lr:  [0.001]\n",
      "Iteration:  45  time:  2.069864422082901e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5220974087715149, 0.317988783121109, 0.079771026968956, 0.15821625292301178, 0.1819135546684265] val loss:  0 lr:  [0.001]\n",
      "Iteration:  50  time:  2.470333129167557e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5600234270095825, 0.3519769012928009, 0.09916950762271881, 0.14680849015712738, 0.1706140637397766] val loss:  0 lr:  [0.001]\n",
      "Iteration:  55  time:  2.3585744202136993e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.516668438911438, 0.18017560243606567, 0.0921950414776802, 0.10888499766588211, 0.1482229381799698] val loss:  0 lr:  [0.001]\n",
      "Iteration:  60  time:  2.4191103875637054e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.549289345741272, 0.10939773917198181, 0.09145698696374893, 0.18132749199867249, 0.17398107051849365] val loss:  0 lr:  [0.001]\n",
      "Iteration:  65  time:  2.4796463549137115e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5250713229179382, 0.21804207563400269, 0.09631240367889404, 0.14901192486286163, 0.17938606441020966] val loss:  0 lr:  [0.001]\n",
      "Iteration:  70  time:  2.400483936071396e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5213983058929443, 0.1778130829334259, 0.10081196576356888, 0.1655285358428955, 0.17143170535564423] val loss:  0 lr:  [0.001]\n",
      "Iteration:  75  time:  2.2491440176963806e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5592391490936279, 0.21583110094070435, 0.08356326818466187, 0.1248156800866127, 0.1566881686449051] val loss:  0 lr:  [0.001]\n",
      "Iteration:  80  time:  2.4796463549137115e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5077798366546631, 0.29827338457107544, 0.10942262411117554, 0.1637398898601532, 0.16997873783111572] val loss:  0 lr:  [0.001]\n",
      "Iteration:  85  time:  2.5797635316848755e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5078327655792236, 0.2728451192378998, 0.10287758708000183, 0.1688484102487564, 0.18831297755241394] val loss:  0 lr:  [0.001]\n",
      "Iteration:  90  time:  2.4191103875637054e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5304563641548157, 0.13531219959259033, 0.0751681923866272, 0.17330877482891083, 0.1839037984609604] val loss:  0 lr:  [0.001]\n",
      "Iteration:  95  time:  2.628657966852188e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5610672831535339, 0.2822573482990265, 0.08744685351848602, 0.15892206132411957, 0.13836517930030823] val loss:  0 lr:  [0.001]\n",
      "Iteration:  100  time:  2.3888424038887024e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.4592549204826355, 0.09594163298606873, 0.0993179902434349, 0.12564145028591156, 0.15586727857589722] val loss:  0 lr:  [0.001]\n",
      "Iteration:  105  time:  2.3585744202136993e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.43930426239967346, 0.10792563855648041, 0.10433586686849594, 0.13337063789367676, 0.18996527791023254] val loss:  0 lr:  [0.001]\n",
      "Iteration:  110  time:  2.461019903421402e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5290126800537109, 0.2390367090702057, 0.08325009793043137, 0.1619301736354828, 0.1658594012260437] val loss:  0 lr:  [0.001]\n",
      "Iteration:  115  time:  2.3795291781425476e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5598155856132507, 0.1830039918422699, 0.09029071033000946, 0.11927573382854462, 0.16318301856517792] val loss:  0 lr:  [0.001]\n",
      "Iteration:  120  time:  2.558808773756027e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5410809516906738, 0.1797952950000763, 0.10259945690631866, 0.139226496219635, 0.1467524915933609] val loss:  0 lr:  [0.001]\n",
      "Iteration:  125  time:  2.621673047542572e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5154635310173035, 0.22806884348392487, 0.09371531009674072, 0.13251087069511414, 0.13642998039722443] val loss:  0 lr:  [0.001]\n",
      "Iteration:  130  time:  2.1094456315040588e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5465372204780579, 0.23029467463493347, 0.08504115790128708, 0.17120227217674255, 0.14442268013954163] val loss:  0 lr:  [0.001]\n",
      "Iteration:  135  time:  2.5890767574310303e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.48322612047195435, 0.16384372115135193, 0.10236454010009766, 0.11674940586090088, 0.15105432271957397] val loss:  0 lr:  [0.001]\n",
      "Iteration:  140  time:  5.159527063369751e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5084739327430725, 0.11273998022079468, 0.08962006866931915, 0.1282098889350891, 0.14548394083976746] val loss:  0 lr:  [0.001]\n",
      "Iteration:  145  time:  2.6705674827098846e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5277122259140015, 0.12406162917613983, 0.09178036451339722, 0.12276013195514679, 0.14442822337150574] val loss:  0 lr:  [0.001]\n",
      "Iteration:  150  time:  2.2887252271175385e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5337997078895569, 0.13207539916038513, 0.0751984491944313, 0.10025923699140549, 0.13723719120025635] val loss:  0 lr:  [0.001]\n",
      "Iteration:  155  time:  2.728775143623352e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5256334543228149, 0.1721639186143875, 0.09563218057155609, 0.1667642891407013, 0.14697474241256714] val loss:  0 lr:  [0.001]\n",
      "Iteration:  160  time:  2.069864422082901e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.49864858388900757, 0.210675910115242, 0.09700906276702881, 0.1303926706314087, 0.15956896543502808] val loss:  0 lr:  [0.001]\n",
      "Iteration:  165  time:  1.878943294286728e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5121228694915771, 0.2949567437171936, 0.07762174308300018, 0.1448228657245636, 0.1522456407546997] val loss:  0 lr:  [0.001]\n",
      "Iteration:  170  time:  2.3399479687213898e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5110768675804138, 0.15862926840782166, 0.09380101412534714, 0.16415375471115112, 0.14698852598667145] val loss:  0 lr:  [0.001]\n",
      "Iteration:  175  time:  2.461019903421402e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.537968635559082, 0.2122330516576767, 0.08344337344169617, 0.10307607799768448, 0.1432766318321228] val loss:  0 lr:  [0.001]\n",
      "Iteration:  180  time:  2.828892320394516e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5476974248886108, 0.19294866919517517, 0.09255777299404144, 0.12220899760723114, 0.14888986945152283] val loss:  0 lr:  [0.001]\n",
      "Iteration:  185  time:  2.4191103875637054e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5469573140144348, 0.2627289295196533, 0.09934172034263611, 0.17693060636520386, 0.15372420847415924] val loss:  0 lr:  [0.001]\n",
      "Iteration:  190  time:  2.300366759300232e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.553745687007904, 0.26545149087905884, 0.0989961251616478, 0.12228009104728699, 0.17137347161769867] val loss:  0 lr:  [0.001]\n",
      "Iteration:  195  time:  2.2910535335540771e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5477123856544495, 0.17264339327812195, 0.08887666463851929, 0.12966987490653992, 0.1712041199207306] val loss:  0 lr:  [0.001]\n",
      "Iteration:  200  time:  2.7497299015522003e-07 dict_keys(['loss_cls', 'loss_box_reg', 'redshift_loss', 'loss_rpn_cls', 'loss_rpn_loc']) [0.5403925180435181, 0.33328306674957275, 0.10498718917369843, 0.17166629433631897, 0.1610940396785736] val loss:  0 lr:  [0.001]\n",
      "saving test_informer\n",
      "Inserting handle into data store.  model_Inform_DeepDISC: inprogress_test_informer.pkl, Inform_DeepDISC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rail.core.data.ModelHandle at 0x7fffb3825520>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inform.inform(training, metadatahandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c69b958",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7360caf2-5b3d-4998-be0c-3ca28fb5e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator = DeepDiscEstimator.make_stage(name='DeepDiscEstimator',\n",
    "#                                       model=Inform.get_handle('model'), **deep_dict)\n",
    "\n",
    "Estimator = DeepDiscPDFEstimator.make_stage(\n",
    "    name=\"DeepDiscEstimator\",\n",
    "    model=Inform.get_handle(\"model\"),\n",
    "    hdf5_groupname=None,\n",
    "    **deep_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c74bb222-f53c-415c-acab-f8b978a2af5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/01 16:58:02 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /home/g4merz/deepdisc/Swin_test.pth ...\n",
      "Processing Data\n",
      "Matching objects\n",
      "Inserting handle into data store.  output_DeepDiscEstimator: inprogress_output_DeepDiscEstimator.hdf5, DeepDiscEstimator\n"
     ]
    }
   ],
   "source": [
    "results = Estimator.estimate(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b402ba2-3779-44e7-8654-113f19731464",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = results.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42326512-837e-4ac6-87c6-2d59c90312db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qp.ensemble.Ensemble at 0x7ffdb9c1bf70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7417fa3-0c51-4a04-837c-f9e54431eeda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rail_deepdisc39",
   "language": "python",
   "name": "rail_deepdisc39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
