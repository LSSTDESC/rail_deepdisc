{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c2a2dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training script for LazyConfig models\n",
    "try:\n",
    "    # ignore ShapelyDeprecationWarning from fvcore\n",
    "    import warnings\n",
    "\n",
    "    from shapely.errors import ShapelyDeprecationWarning\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning)\n",
    "\n",
    "except:\n",
    "    pass\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "\n",
    "import detectron2.utils.comm as comm\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.config import LazyConfig, get_cfg\n",
    "import detectron2.data as data\n",
    "from detectron2.engine import (\n",
    "    launch,\n",
    ")\n",
    "\n",
    "from deepdisc.data_format.augment_image import train_augs\n",
    "from deepdisc.data_format.image_readers import DC2ImageReader\n",
    "from deepdisc.data_format.register_data import (\n",
    "    register_data_set,\n",
    ")  # , register_loaded_data_set\n",
    "from deepdisc.model.loaders import (\n",
    "    RedshiftFlatDictMapper,\n",
    "    return_test_loader,\n",
    "    return_train_loader,\n",
    ")\n",
    "from deepdisc.model.models import (\n",
    "    RedshiftPointCasROIHeads,\n",
    "    RedshiftPointROIHeads,\n",
    "    RedshiftPDFROIHeads,\n",
    "    return_lazy_model,\n",
    ")\n",
    "from deepdisc.training.trainers import (\n",
    "    return_evallosshook,\n",
    "    return_lazy_trainer,\n",
    "    return_optimizer,\n",
    "    return_savehook,\n",
    "    return_schedulerhook,\n",
    ")\n",
    "from deepdisc.utils.parse_arguments import make_training_arg_parser\n",
    "from deepdisc.inference.predictors import return_predictor_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5244b7ff-1501-47ad-b74e-c575f9758089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rail.estimation.algos.deepdisc import DeepDiscInformer\n",
    "import rail\n",
    "from rail.estimation.algos.deepdisc import *\n",
    "from rail.core.data import TableHandle, JsonHandle\n",
    "from rail.core.stage import RailStage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e82e6de-f6ec-46b5-a6a7-60e79cd79c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cfgfile = \"./tests/configs/solo/solo_res50_DC2.py\"\n",
    "cfgfile = \"./configs/solo/solo_swin_DC2.py\"\n",
    "\n",
    "output_dir = \"./\"\n",
    "output_name = \"test\"\n",
    "\n",
    "trainfile = \"/home/shared/hsc/DC2/test_data/dataset_3/flattened_images_train.hdf5\"\n",
    "testfile = \"/home/shared/hsc/DC2/test_data/dataset_3/flattened_images_test.hdf5\"\n",
    "metadatafile = \"/home/shared/hsc/DC2/test_data/dataset_3/train_metadata.hdf5\"\n",
    "test_metadatafile = \"/home/shared/hsc/DC2/test_data/dataset_3/test_metadata.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffd06982-1e98-4b8a-a3a8-b68ac71cd6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01f48f9e-16a3-423d-a550-ed9298b6fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = DS.add_data(\n",
    "    \"training\", data=None, handle_class=TableHandle, path=trainfile\n",
    ")  # ()[\"images\"]\n",
    "testing = DS.add_data(\"testing\", data=None, handle_class=TableHandle, path=testfile)\n",
    "\n",
    "#metadatahandle = DS.add_data(\"metadata\", metadata, JsonHandle, path=metadatafile)\n",
    "metadatahandle = DS.add_data(\"metadata\", data=None, handle_class=Hdf5Handle, path=metadatafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a89bda8-fd14-4e15-a810-89da7b79f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_file_for_chunks = \"/home/shared/hsc/DC2/test_data/dataset_3/flattened_images_test_small.hdf5\"\n",
    "#test_handle_for_chunks = DS.add_data(\"testing\", data=None, handle_class=TableHandle, path=test_file_for_chunks)\n",
    "#metadatafile_with_chunks = \"/home/shared/hsc/DC2/test_data/dataset_3/test_metadata_example.hdf5\"\n",
    "#metadatahandle_with_chunks = DS.add_data(\"metadata\", metadata, Hdf5Handle, path=metadatafile_with_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a57e206a-c5c6-4526-a278-868ef2a6047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_dict = dict(\n",
    "    chunk_size=5,\n",
    "    epoch=20,\n",
    "    batch_size=1,\n",
    "    output_dir=\"./\",\n",
    "    cfgfile = cfgfile,\n",
    "    num_gpus=1,\n",
    "    print_frequency=5,\n",
    "    head_epochs=1,\n",
    "    full_epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d611ae20-a7c7-4f52-9390-1d27eca138f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inform = DeepDiscInformer.make_stage(\n",
    "    name=\"Inform_DeepDISC\", model=\"test_informer.pkl\", **deep_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b6a9d1-697e-4bde-abee-e519253daa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inform.inform(training, metadatahandle)\n",
    "Inform.inform(training, metadatahandle) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c69b958",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070dcb2-0de8-42af-af8d-f40c689b7cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadatahandle = DS.add_data(\n",
    "#     \"metadata\", test_metadata, JsonHandle, path=test_metadatafile\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7360caf2-5b3d-4998-be0c-3ca28fb5e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator = DeepDiscPDFEstimator.make_stage(\n",
    "#     name=\"DeepDiscEstimator\",\n",
    "#     model=Inform.get_handle(\"model\"),\n",
    "#     # hdf5_groupname=\"images\",\n",
    "#     **deep_dict,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6415a174-6d14-48f5-9241-963a84431501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Estimator.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74bb222-f53c-415c-acab-f8b978a2af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = Estimator.estimate(testing, metadatahandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b402ba2-3779-44e7-8654-113f19731464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = results.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d2b4a5-0422-4f8f-8e08-49811549c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# truth = Estimator.get_handle(\"truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94da4c4a-93c6-4203-a1b3-4fe186bad242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ztrue = truth.data[\"redshift\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e48290de-6f18-422c-9b04-c6aaec97439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.core.data import ModelHandle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c712fc8-1e60-4389-86fb-2864922fe19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MH = ModelHandle('model',path='./test_informer.pkl')\n",
    "data = MH.read()\n",
    "#MH()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d5c4f6f-2929-4653-b89c-29c94aae92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgfile = \"./configs/solo/solo_swin_DC2.py\"\n",
    "cfg = LazyConfig.load(cfgfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26bfb59c-5bbc-42c3-b320-7bef7386cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MH()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d7cfa05-5bcf-45dc-b1f1-fb25128da2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = MH()['nnmodel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c2806-5bb6-4781-afd0-1c122199877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint=Inform.get_handle(\"model\")\n",
    "#help(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58934320-d950-49e0-b2af-0c9b2e21cb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\n"
     ]
    }
   ],
   "source": [
    "#predictor = return_predictor_transformer(cfg, checkpoint=checkpoint)\n",
    "import deepdisc.astrodet.astrodet as toolkit\n",
    "predictor = toolkit.AstroPredictor(cfg,checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a243e22-46b1-47a2-9c31-9e0746dbee7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d93d6cc-333c-4c28-b5df-f295433cc9e7",
   "metadata": {},
   "source": [
    "## Test new chunking algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48936320-ed0f-40c3-8329-1f3e2c7c31ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_estimation_dict = dict(\n",
    "    chunk_size=5,\n",
    "    output_dir=\"./\",\n",
    "    cfgfile = cfgfile,\n",
    "    zmin=0,\n",
    "    zmax=5,\n",
    "    nzbins=200,\n",
    "    output_mode='default',\n",
    ")\n",
    "\n",
    "EstimatorWithChunks = DeepDiscPDFEstimatorWithChunking.make_stage(\n",
    "    name=\"DeepDiscEstimatorWithChunks\",\n",
    "    #model=Inform.get_handle(\"model\"),\n",
    "    model=MH,\n",
    "    **deep_estimation_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31f8a0c3-6ad4-430c-9892-b70ae4285ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_for_chunks = \"/home/shared/hsc/DC2/test_data/dataset_3/flattened_images_test_small.hdf5\"\n",
    "test_handle_for_chunks = DS.add_data(\"testing\", data=None, handle_class=TableHandle, path=test_file_for_chunks)\n",
    "metadatafile_with_chunks = \"/home/shared/hsc/DC2/test_data/dataset_3/test_metadata_example.hdf5\"\n",
    "metadatahandle_with_chunks = DS.add_data(\"metadata\", data=None, handle_class=Hdf5Handle, path=metadatafile_with_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c684e258-6c71-476f-bf35-79b53df86282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  model: ./test_informer.pkl, DeepDiscEstimatorWithChunks\n",
      "Caching data\n",
      "Processing chunk (start:end) - (0:5)\n",
      "Matching objects\n",
      "\u001b[32m[01/09 21:04:19 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "Matching objects\n",
      "\u001b[32m[01/09 21:04:19 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/09 21:04:19 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/09 21:04:19 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/09 21:04:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.29 MiB\n",
      "\u001b[32m[01/09 21:04:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.29 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g4merz/.conda/envs/ddrailnv/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /data/miniconda3/envs/opence-1.7/conda-bld/pytorch-base_1672876060819/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/g4merz/.conda/envs/ddrailnv/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /data/miniconda3/envs/opence-1.7/conda-bld/pytorch-base_1672876060819/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "ProcessRaisedException",
     "evalue": "\n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/g4merz/.conda/envs/ddrailnv/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/home/g4merz/detectron2/detectron2/engine/launch.py\", line 123, in _distributed_worker\n    main_func(*args)\n  File \"/home/g4merz/rail_deepdisc/src/rail/estimation/algos/deepdisc.py\", line 410, in _do_inference\n    dist.gather(pdfs, gather_list=[], dst=0, group=group)\n  File \"/home/g4merz/.conda/envs/ddrailnv/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py\", line 2513, in gather\n    _check_single_tensor(tensor, \"tensor\")\n  File \"/home/g4merz/.conda/envs/ddrailnv/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py\", line 463, in _check_single_tensor\n    raise RuntimeError(\nRuntimeError: Invalid function argument. Expected parameter `tensor` to be of type torch.Tensor.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results_from_chunks \u001b[38;5;241m=\u001b[39m \u001b[43mEstimatorWithChunks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_handle_for_chunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatahandle_with_chunks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rail_deepdisc/src/rail/estimation/algos/deepdisc.py:448\u001b[0m, in \u001b[0;36mDeepDiscPDFEstimatorWithChunking.estimate\u001b[0;34m(self, input_data, input_metadata)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_data)\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_metadata)\n\u001b[0;32m--> 448\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_handle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/rail_deepdisc/src/rail/estimation/algos/deepdisc.py:495\u001b[0m, in \u001b[0;36mDeepDiscPDFEstimatorWithChunking.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# process this chunk of data\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing chunk (start:end) - (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 495\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rail_deepdisc/src/rail/estimation/algos/deepdisc.py:513\u001b[0m, in \u001b[0;36mDeepDiscPDFEstimatorWithChunking._process_chunk\u001b[0;34m(self, start_idx, metadata, rank, size)\u001b[0m\n\u001b[1;32m    510\u001b[0m q \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mQueue()\n\u001b[1;32m    512\u001b[0m \u001b[38;5;66;03m# call detectron2's `launch` function to parallelize the inference\u001b[39;00m\n\u001b[0;32m--> 513\u001b[0m \u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_do_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_gpus_per_machine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#! correct this to be a StageParam\u001b[39;49;00m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_machines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#! correct this to be a StageParam\u001b[39;49;00m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmachine_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#? Need to figure out how to get this, maybe from the comm? or ceci???\u001b[39;49;00m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdist_url\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_get_dist_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzgrid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;66;03m# grab the output qp.Ensemble from the queue\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;66;03m#! should guard this in case the queue is empty\u001b[39;00m\n\u001b[1;32m    530\u001b[0m qp_dstn \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m~/detectron2/detectron2/engine/launch.py:69\u001b[0m, in \u001b[0;36mlaunch\u001b[0;34m(main_func, num_gpus_per_machine, num_machines, machine_rank, dist_url, args, timeout)\u001b[0m\n\u001b[1;32m     64\u001b[0m         logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     65\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile:// is not a reliable init_method in multi-machine jobs. Prefer tcp://\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m         )\n\u001b[0;32m---> 69\u001b[0m     \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_distributed_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_gpus_per_machine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmain_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_gpus_per_machine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmachine_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdist_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m     main_func(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/.conda/envs/ddrailnv/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:198\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ddrailnv/lib/python3.9/site-packages/torch/multiprocessing/spawn.py:160\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    158\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Process \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m error_index\n\u001b[1;32m    159\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m original_trace\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process\u001b[38;5;241m.\u001b[39mpid)\n",
      "\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/g4merz/.conda/envs/ddrailnv/lib/python3.9/site-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n    fn(i, *args)\n  File \"/home/g4merz/detectron2/detectron2/engine/launch.py\", line 123, in _distributed_worker\n    main_func(*args)\n  File \"/home/g4merz/rail_deepdisc/src/rail/estimation/algos/deepdisc.py\", line 410, in _do_inference\n    dist.gather(pdfs, gather_list=[], dst=0, group=group)\n  File \"/home/g4merz/.conda/envs/ddrailnv/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py\", line 2513, in gather\n    _check_single_tensor(tensor, \"tensor\")\n  File \"/home/g4merz/.conda/envs/ddrailnv/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py\", line 463, in _check_single_tensor\n    raise RuntimeError(\nRuntimeError: Invalid function argument. Expected parameter `tensor` to be of type torch.Tensor.\n"
     ]
    }
   ],
   "source": [
    "results_from_chunks = EstimatorWithChunks.estimate(test_handle_for_chunks, metadatahandle_with_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cad19c-d31c-4e0c-b684-82c79534c44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f2a02-2aec-46cb-b963-c32b3caa0711",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ens = results_from_chunks.read()\n",
    "res_ens.npdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a8f659-bc35-47d0-abd4-f0a662330a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f3aa7a3-c530-4882-95ea-12b07252cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_iterator = EstimatorWithChunks.input_iterator(\"metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cfd618c-eb6d-4a83-b678-5971ff384570",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,metadata_json_dicts = next(metadata_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e80c7bab-8bec-40f0-af28-0298390e0b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['metadata_dicts'])\n"
     ]
    }
   ],
   "source": [
    "print(metadata_json_dicts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "439955db-507f-44a8-ba9a-0e31db5403a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = [json.loads(this_json) for this_json in metadata_json_dicts['metadata_dicts']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d29d59-e6a4-47ad-8648-e81243483484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(metadata[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae973cd-8e45-4f70-b12b-2f6dbf01570c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b958d33f-c330-4149-aa97-fe1970555bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.evaluation.evaluator import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18e185eb-397a-41b8-978e-871a9f624cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_eval_dict = dict(\n",
    "    chunk_size=100,\n",
    "    zmin=-1,\n",
    "    zmax=5,\n",
    "    nzbins=200,\n",
    "    epochs=20,\n",
    "    output_name=\"test_evaluator\",\n",
    "    point_metrics=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7417fa3-0c51-4a04-837c-f9e54431eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepEvaluator = Evaluator.make_stage(name=\"DeepDiscEvaluator\", **deep_eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7ba5ca0-7ded-4b4c-ac63-264c8c23ec98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eval_res \u001b[38;5;241m=\u001b[39m DeepEvaluator\u001b[38;5;241m.\u001b[39mevaluate(\u001b[43mres\u001b[49m, truth)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "eval_res = DeepEvaluator.evaluate(res, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf80908-9582-45ca-b78f-f5163fb415a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_res.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f874ba48-786b-46d9-845d-d659c86cdc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qp.metrics.pit import PIT\n",
    "from utils import *  # plot_pit_qq, ks_plot\n",
    "\n",
    "pitobj = PIT(res, ztrue)\n",
    "pit_out_rate = pitobj.evaluate_PIT_outlier_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6de28b4-61c2-4d6f-ab20-46a0d369364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qp.ensemble import Ensemble\n",
    "\n",
    "\n",
    "class Sample(Ensemble):\n",
    "    \"\"\"Expand qp.Ensemble to append true redshifts\n",
    "    array, metadata, and specific plots.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, pdfs, zgrid, ztrue, photoz_mode=None, code=\"\", name=\"\", n_quant=100\n",
    "    ):\n",
    "        \"\"\"Class constructor\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pdfs: `ndarray`\n",
    "            photo-z PDFs array, shape=(Ngals, Nbins)\n",
    "        zgrid: `ndarray`\n",
    "            PDF bins centers, shape=(Nbins,)\n",
    "        ztrue: `ndarray`\n",
    "            true redshifts, shape=(Ngals,)\n",
    "        photoz_mode: `ndarray`\n",
    "            photo-z (PDF mode), shape=(Ngals,)\n",
    "        code: `str`, (optional)\n",
    "            algorithm name (for plot legends)\n",
    "        name: `str`, (optional)\n",
    "            sample name (for plot legends)\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(interp, data=dict(xvals=zgrid, yvals=pdfs))\n",
    "        self._pdfs = pdfs\n",
    "        self._zgrid = zgrid\n",
    "        self._ztrue = ztrue\n",
    "        self._photoz_mode = photoz_mode\n",
    "        self._code = code\n",
    "        self._name = name\n",
    "        self._n_quant = n_quant\n",
    "        self._pit = None\n",
    "        self._qq = None\n",
    "\n",
    "    @property\n",
    "    def code(self):\n",
    "        \"\"\"Photo-z code/algorithm name\"\"\"\n",
    "        return self._code\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        \"\"\"Sample name\"\"\"\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def ztrue(self):\n",
    "        \"\"\"True redshifts array\"\"\"\n",
    "        return self._ztrue\n",
    "\n",
    "    @property\n",
    "    def zgrid(self):\n",
    "        \"\"\"Redshift grid (binning)\"\"\"\n",
    "        return self._zgrid\n",
    "\n",
    "    @property\n",
    "    def photoz_mode(self):\n",
    "        \"\"\"Photo-z (mode) array\"\"\"\n",
    "        return self._photoz_mode\n",
    "\n",
    "    @property\n",
    "    def n_quant(self):\n",
    "        return self._n_quant\n",
    "\n",
    "    @property\n",
    "    def pit(self):\n",
    "        if self._pit is None:\n",
    "            pit_array = np.array(\n",
    "                [self[i].cdf(self.ztrue[i])[0][0] for i in range(len(self))]\n",
    "            )\n",
    "            self._pit = pit_array\n",
    "        return self._pit\n",
    "\n",
    "    @property\n",
    "    def qq(self, n_quant=100):\n",
    "        q_theory = np.linspace(0.0, 1.0, n_quant)\n",
    "        q_data = np.quantile(self.pit, q_theory)\n",
    "        self._qq = (q_theory, q_data)\n",
    "        return self._qq\n",
    "\n",
    "    def __len__(self):\n",
    "        if len(self._ztrue) != len(self._pdfs):\n",
    "            raise ValueError(\"Number of pdfs and true redshifts do not match!!!\")\n",
    "        return len(self._ztrue)\n",
    "\n",
    "    def __str__(self):\n",
    "        code_str = f\"Algorithm: {self._code}\"\n",
    "        name_str = f\"Sample: {self._name}\"\n",
    "        line_str = \"-\" * (max(len(code_str), len(name_str)))\n",
    "        text = str(\n",
    "            line_str\n",
    "            + \"\\n\"\n",
    "            + name_str\n",
    "            + \"\\n\"\n",
    "            + code_str\n",
    "            + \"\\n\"\n",
    "            + line_str\n",
    "            + \"\\n\"\n",
    "            + f\"{len(self)} PDFs with {len(self.zgrid)} probabilities each \\n\"\n",
    "            + f\"qp representation: {self.gen_class.name} \\n\"\n",
    "            + f\"z grid: {len(self.zgrid)} z values from {np.min(self.zgrid)} to {np.max(self.zgrid)} inclusive\"\n",
    "        )\n",
    "        return text\n",
    "\n",
    "    def plot_pdfs(self, gals, show_ztrue=True, show_photoz_mode=False):\n",
    "        colors = plot_pdfs(\n",
    "            self, gals, show_ztrue=show_ztrue, show_photoz_mode=show_photoz_mode\n",
    "        )\n",
    "        return colors\n",
    "\n",
    "    def plot_old_valid(self, gals=None, colors=None):\n",
    "        old_metrics_table = plot_old_valid(self, gals=gals, colors=colors)\n",
    "        return old_metrics_table\n",
    "\n",
    "    def plot_pit_qq(\n",
    "        self,\n",
    "        bins=None,\n",
    "        label=None,\n",
    "        title=None,\n",
    "        show_pit=True,\n",
    "        show_qq=True,\n",
    "        show_pit_out_rate=True,\n",
    "        savefig=False,\n",
    "    ):\n",
    "        \"\"\"Make plot PIT-QQ as Figure 2 from Schmidt et al. 2020.\"\"\"\n",
    "        fig_filename = plot_pit_qq(\n",
    "            self,\n",
    "            bins=bins,\n",
    "            label=label,\n",
    "            title=title,\n",
    "            show_pit=show_pit,\n",
    "            show_qq=show_qq,\n",
    "            show_pit_out_rate=show_pit_out_rate,\n",
    "            savefig=savefig,\n",
    "        )\n",
    "        return fig_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee26258c-8401-45ed-a75d-92da6ed7f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pit_qq(\n",
    "    pdfs,\n",
    "    zgrid,\n",
    "    ztrue,\n",
    "    bins=None,\n",
    "    title=None,\n",
    "    code=None,\n",
    "    show_pit=True,\n",
    "    show_qq=True,\n",
    "    pit_out_rate=None,\n",
    "    savefig=False,\n",
    ") -> str:\n",
    "    \"\"\"Quantile-quantile plot\n",
    "        Ancillary function to be used by class Metrics.\n",
    "    â€‹\n",
    "        Parameters\n",
    "        ----------\n",
    "        pit: `PIT` object\n",
    "            class from metrics.py\n",
    "        bins: `int`, optional\n",
    "            number of PIT bins\n",
    "            if None, use the same number of quantiles (sample.n_quant)\n",
    "        title: `str`, optional\n",
    "            if None, use formatted sample's name (sample.name)\n",
    "        label: `str`, optional\n",
    "            if None, use formatted code's name (sample.code)\n",
    "        show_pit: `bool`, optional\n",
    "            include PIT histogram (default=True)\n",
    "        show_qq: `bool`, optional\n",
    "            include QQ plot (default=True)\n",
    "        pit_out_rate: `ndarray`, optional\n",
    "            print metric value on the plot panel (default=None)\n",
    "        savefig: `bool`, optional\n",
    "            save plot in .png file (default=False)\n",
    "    \"\"\"\n",
    "\n",
    "    if bins is None:\n",
    "        bins = 100\n",
    "    if title is None:\n",
    "        title = \"\"\n",
    "\n",
    "    if code is None:\n",
    "        code = \"\"\n",
    "        label = \"\"\n",
    "    else:\n",
    "        label = code + \"\\n\"\n",
    "\n",
    "    if pit_out_rate is not None:\n",
    "        try:\n",
    "            label += \"PIT$_{out}$: \"\n",
    "            label += f\"{float(pit_out_rate):.4f}\"\n",
    "        except:\n",
    "            print(\"Unsupported format for pit_out_rate.\")\n",
    "\n",
    "    plt.figure(figsize=[4, 5])\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[3, 1])\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    sample = Sample(pdfs, zgrid, ztrue)\n",
    "\n",
    "    if show_qq:\n",
    "        ax0.plot(\n",
    "            sample.qq[0], sample.qq[1], c=\"r\", linestyle=\"-\", linewidth=3, label=label\n",
    "        )\n",
    "        ax0.plot([0, 1], [0, 1], color=\"k\", linestyle=\"--\", linewidth=2)\n",
    "        ax0.set_ylabel(\"Q$_{data}$\", fontsize=18)\n",
    "        plt.ylim(-0.001, 1.001)\n",
    "    plt.xlim(-0.001, 1.001)\n",
    "    plt.title(title)\n",
    "    if show_pit:\n",
    "        fzdata = Ensemble(interp, data=dict(xvals=zgrid, yvals=pdfs))\n",
    "        pitobj = PIT(fzdata, ztrue)\n",
    "        pit_vals = np.array(pitobj.pit_samps)\n",
    "        pit_out_rate = pitobj.evaluate_PIT_outlier_rate()\n",
    "\n",
    "        try:\n",
    "            y_uni = float(len(pit_vals)) / float(bins)\n",
    "        except:\n",
    "            y_uni = float(len(pit_vals)) / float(len(bins))\n",
    "        if not show_qq:\n",
    "            ax0.hist(pit_vals, bins=bins, alpha=0.7, label=label)\n",
    "            ax0.set_ylabel(\"Number\")\n",
    "            ax0.hlines(y_uni, xmin=0, xmax=1, color=\"k\")\n",
    "            plt.ylim(\n",
    "                0,\n",
    "            )  # -0.001, 1.001)\n",
    "        else:\n",
    "            ax1 = ax0.twinx()\n",
    "            ax1.hist(pit_vals, bins=bins, alpha=0.7)\n",
    "            ax1.set_ylabel(\"Number\")\n",
    "            ax1.hlines(y_uni, xmin=0, xmax=1, color=\"k\")\n",
    "    leg = ax0.legend(handlelength=0, handletextpad=0, fancybox=True)\n",
    "    for item in leg.legendHandles:\n",
    "        item.set_visible(False)\n",
    "    if show_qq:\n",
    "        ax2 = plt.subplot(gs[1])\n",
    "        ax2.plot(\n",
    "            sample.qq[0],\n",
    "            (sample.qq[1] - sample.qq[0]),\n",
    "            c=\"r\",\n",
    "            linestyle=\"-\",\n",
    "            linewidth=3,\n",
    "        )\n",
    "        plt.ylabel(\"$\\Delta$Q\", fontsize=18)\n",
    "        ax2.plot([0, 1], [0, 0], color=\"k\", linestyle=\"--\", linewidth=2)\n",
    "        plt.xlim(-0.001, 1.001)\n",
    "        plt.ylim(\n",
    "            np.min([-0.12, np.min(sample.qq[1] - sample.qq[0]) * 1.05]),\n",
    "            np.max([0.12, np.max(sample.qq[1] - sample.qq[0]) * 1.05]),\n",
    "        )\n",
    "    if show_pit:\n",
    "        if show_qq:\n",
    "            plt.xlabel(\"Q$_{theory}$ / PIT Value\", fontsize=18)\n",
    "        else:\n",
    "            plt.xlabel(\"PIT Value\", fontsize=18)\n",
    "    else:\n",
    "        if show_qq:\n",
    "            plt.xlabel(\"Q$_{theory}$\", fontsize=18)\n",
    "    if savefig:\n",
    "        fig_filename = str(\"plot_pit_qq_\" + f\"{(code).replace(' ', '_')}.png\")\n",
    "        plt.savefig(fig_filename)\n",
    "    else:\n",
    "        fig_filename = None\n",
    "\n",
    "    return fig_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1263c0-1b38-4042-956c-902f1065c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from qp import interp\n",
    "\n",
    "\n",
    "zgrid = np.linspace(-1, 5, 200)\n",
    "pdfs = res.objdata()[\"yvals\"]\n",
    "plot_pit_qq(\n",
    "    pdfs,\n",
    "    zgrid,\n",
    "    ztrue,\n",
    "    title=\"PIT-QQ - toy data\",\n",
    "    code=\"DeepDISC\",\n",
    "    pit_out_rate=pit_out_rate,\n",
    "    savefig=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb4cfe-af95-45f1-91f1-ed9c08009f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.objdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78982146-0b5d-49d3-bb04-77931ea3aa5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b2cf39-8446-4888-b304-85637c2fba92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229bf0e4-d58f-4383-a77d-478ca07f1120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddrailnv",
   "language": "python",
   "name": "ddrailnv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
